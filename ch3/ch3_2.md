# 欠采样重建

### 1.1 概念与背景

在MRI中，采集 k 空间（频域）数据耗时较长，为了缩短扫描时间，常对k空间进行欠采样（只采集部分 k 空间点），欠采样会在图像域产生混叠或丢失高频细节，欠采样重建目的：在测量数据（欠采样k空间）下恢复高质量图像。

设真实图像为 $x\in\mathbb{C}^{N}$ （展开为矢量），完整的k空间测量为 $y=F x$（ $F$ 为离散傅里叶变换矩阵），欠采样通过一个采样掩码 (M)（对 k 空间下采样）实现观测为

$$
y = M (F x) + \eta,
$$

其中 $M$ 表示只保留部分频谱样本等价于在k空间元素逐点相乘， $\eta$ 为噪声。

目标是从 $y$ 恢复 $x$。欠采样导致线性逆问题不适定（自由度不足），需要先验或正则化（稀疏性、低秩、空间/频率先验、深度网络等）。

### 1.2 常用数学方法

①零填充（Zero-filled）直接逆变换：把未采样点置0，然后做iFFT。简单但有严重混叠伪影。

②线性重建 + 正则化：求解

$$
  \min_x \frac12|M F x - y|_2^2 + \lambda R(x),
$$

其中 $R(x)$ 为正则化项如总变分 TV、图像稀疏性 $L_1$ （小波域）等。

③压缩感知（CS）：利用图像在某基（如小波）上稀疏性，常用 L1 正则化与迭代软阈值（ISTA/FISTA）或 ADMM。

④变分方法（TV, H1）：使用 TV 正则化减少块状伪影。

⑤迭代重建+数据一致性：在每次迭代保持与测量一致（在 k 空间保留采样点），常见于深度学的“unrolled”结构。

⑥字典学习、稀疏编码：学习稀疏表示字典，再重建。

⑦低秩矩阵完成方法：对时间序列或动态图像使用低秩约束。

### 1.3 数学细节示例 — ISTA（简单 L1 稀疏）

目标

$$
\min_x \frac12|A x - y|*2^2 + \lambda |x|*1,
$$

其中 $A = M F$ ，ISTA 迭代

$$
x^{(k+1)} = \mathcal{S}*{\alpha\lambda}\Big( x^{(k)} - \alpha A^H (A x^{(k)} - y)\Big),
$$

$\mathcal{S}*\tau$ 为逐元素软阈值： $\mathcal{S}_\tau(z) = \mathrm{sign}(z)\max(|z|-\tau,0)$ ， $\alpha$ 为步长（小于 $1/|A|_2^2$ ）。

注：上述把稀疏性放在图像域更标准是把稀疏正则放在小波域  $Wx$ 上：$|W x|_1$ ，相应阈值步骤在小波系数域进行需小波变换库。

#### 1.3.1 ISTA示例代码

下面代码展示：1）生成一张合成图像；2）构造欠采样k空间 mask；3）零填充重建；4）用 ISTA 做简单 L1 重建（稀疏在图像域）。

```python
# 文件名：undersampling_ista_demo.py
import numpy as np
import matplotlib.pyplot as plt

def fft2c(x):
    return np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(x)))

def ifft2c(k):
    return np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(k)))

def create_phantom(n=256):
    # 简单合成：两个高斯亮斑
    x = np.linspace(-1,1,n)
    X,Y = np.meshgrid(x,x)
    img = np.exp(-((X-0.3)**2+(Y-0.2)**2)/(0.03)) + 0.8*np.exp(-((X+0.25)**2+(Y-0.25)**2)/(0.02))
    return img

def random_mask(shape, accel_factor=4, center_frac=0.08):
    # 生成随机径向方向欠采样的mask
    nx, ny = shape
    mask = np.zeros((nx, ny), dtype=np.float32)
    # 保留中心低频
    cx = ny//2
    radius = int(center_frac * ny/2)
    mask[:, cx-radius:cx+radius] = 1
    # 随机选择其余列以满足加速因子
    prob = 1.0/accel_factor
    for j in range(ny):
        if np.random.rand() < prob:
            mask[:, j] = 1
    return mask

def soft_threshold(z, thresh):
    return np.sign(z) * np.maximum(np.abs(z) - thresh, 0.0)

def ista_reconstruct(y, mask, lam=0.01, n_iter=100, step=1.0):
    nx, ny = mask.shape
    x = ifft2c(y * mask)  # init: zero-filled
    for it in range(n_iter):
        Ax = fft2c(x) * mask
        grad = ifft2c((Ax - y) * mask)
        x = soft_threshold(x - step * grad, lam*step)
        if it % 20 == 0:
            print(f"Iter {it}")
    return x

def main():
    n = 256
    img = create_phantom(n)
    k_full = fft2c(img)
    mask = random_mask((n,n), accel_factor=6, center_frac=0.08)
    y = k_full * mask  
    # zero-filled
    zf = np.abs(ifft2c(y))
    # ISTA
    rec = ista_reconstruct(y, mask, lam=0.02, n_iter=200, step=0.8)
    rec_abs = np.abs(rec)
    # display
    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1); plt.imshow(img, cmap='gray'); plt.title("原始")
    plt.subplot(1,3,2); plt.imshow(zf, cmap='gray'); plt.title("Zero-filled")
    plt.subplot(1,3,3); plt.imshow(rec_abs, cmap='gray'); plt.title("ISTA 重建")
    plt.show()

if __name__ == "__main__":
    main()
```

说明：

①这是一个教学示例，稀疏先验放在图像域，真实MRI常在小波域或梯度域使用 $L_1$ 、TV。

②`mask` 使用列随机采样并保留中心低频模仿常见策略（实际设计如 Variable-density Poisson-disc sampling 更合适）。

③ISTA收敛较慢，FISTA（带动量）速度更快。

### 1.4 总变分（TV）正则化示例（简要）

TV 正则化目标：

$$
\min_x \frac12|A x - y|_2^2 + \lambda \mathrm{TV}(x),
$$

$\mathrm{TV}(x)=\sum_i \sqrt{|D_x x_i|^2 + |D_y x_i|^2}$ ,可用Chambolle-Pock, ADMM等算法求解。代码较长，此处不展开实现细节，但可在GitHub示例中提供基于 `scipy` 的实现或调用现成库如 `proxTV`、`skimage.restoration.denoise_tv_chambolle` 等做演示。

### 1.5 实践建议与注意事项

* 欠采样策略影响伪影类型：周期性规则欠采样造成条纹状混叠，而随机/可变密度采样造成噪声样伪影，更利于 CS/深度方法恢复。
* 数据一致性（Data Consistency, DC）在现代方法中必不可少，尤其在深度学习中常在每个迭代/模块中强制 k 空间已采样点与测量一致。
* 正则化参数 (\lambda) 需调参（交叉验证或经验法）。
* 真实 MRI 数据具有相位，通常处理复数数据（实部+虚部或幅值+相位）；示例为实值便于演示。
* 使用真实临床数据（如 fastMRI）进行训练/验证更能体现方法性能。


## 2 并行成像重建

### 2.1 背景

多接收线圈（coil）在空间上敏感度不同，允许在每个相位编码steg降低采样密度同时用多个线圈的冗余信息恢复图像，从而加速扫描（加速因子 R）。两类主流并行成像方法：

①基于图像域的SENSE：利用已知/估计的线圈空间敏感度maps，在图像域做像素级线性反演。

②基于 k 空间插值的GRAPPA：在 k 空间用邻域整形算子插值未采样的 k 点，系数由自校正信号（ACS）估计。

#### 2.2 SENSE（图像域）

原理：每个线圈采到的图像是真实图像 $x(\mathbf r)$ 与该线圈敏感度 $s_c(\mathbf r)$ 的乘积（再加噪声），即

$$
d_c(\mathbf r) = s_c(\mathbf r) x(\mathbf r) + n_c(\mathbf r), \quad c=1,\dots,C.
$$

对于欠采样（加速因子R）造成混叠：图像空间某像素点变成多个折叠位置的叠加。SENSE 将每个被折叠的像素位置的多个线圈观测写成线性方程组，利用线圈敏感度矩阵求解局部解。

离散化，设某折叠位置集合为 $x_\text{fold}\in\mathbb{C}^R$ ，线圈观测 $d\in\mathbb{C}^C$ ，灵敏度矩阵 $S\in\mathbb{C}^{C\times R}$ ，则

$$
d = S x_\text{fold} + n.
$$

若 $C \ge R$ 且 $S$ 条件良好，可用最小二乘估计：

$$
\hat x_\text{fold} = (S^H S)^{-1} S^H d.
$$

若噪声协方差 $\Psi$ 非单位，则用加权最小二乘：

$$
\hat x = (S^H \Psi^{-1} S)^{-1} S^H \Psi^{-1} d.
$$

关键点：需要准确的线圈敏感度地图 $s_c(\mathbf r)$ 。常通过独立的灵敏度扫描或用自校准数据（ACS）估计。

#### 2.2.1 SENSE 简单实现（模拟）

思路：

1. 模拟若干 coil 的敏感度 maps（例如平滑相位/幅度分布）。
2. 由真图 (x) 与每个 coil 的敏感度乘积得到 coil 图像。
3. 每个 coil 做 k 空间傅里叶变换并按加速因子欠采样（保留部分相位编码行）。
4. 在图像域对每个 coil 做逆变换得到折叠图（带混叠）。
5. 对每个折叠像素位置用线性求逆（SENSE）恢复。

```python
import numpy as np
import matplotlib.pyplot as plt
from numpy.fft import fft2, ifft2, fftshift, ifftshift

def fft2c(x): return fftshift(fft2(ifftshift(x)))
def ifft2c(k): return fftshift(ifft2(ifftshift(k)))

def simulate_sensitivity_maps(nx, ny, C):
    x = np.linspace(-1,1,nx)
    y = np.linspace(-1,1,ny)
    X, Y = np.meshgrid(x,y, indexing='ij')
    maps = np.zeros((C,nx,ny), dtype=np.complex128)
    for c in range(C):
        angle = np.pi * c / C
        maps[c] = (1.0 + 0.5*(X*np.cos(angle)+Y*np.sin(angle))) * np.exp(1j*(0.2*c*X + 0.1*c*Y))
    return maps

def create_phantom(n=128):
    x = np.linspace(-1,1,n)
    X, Y = np.meshgrid(x,x)
    img = np.exp(-((X-0.3)**2+(Y-0.2)**2)/(0.02)) + 0.8*np.exp(-((X+0.25)**2+(Y+0.25)**2)/(0.01))
    return img

def undersample_kspace(kspace, R):
    # 以相位编码方向按 R 下采样（保留中心低频）
    nx, ny = kspace.shape[1], kspace.shape[2]
    mask = np.zeros((nx, ny))
    # keep center
    center = ny//2
    keep = int(ny//(2*R))
    mask[:, center-keep:center+keep] = 1
    # pick every Rth line outside center
    for j in range(ny):
        if mask[0,j]==0 and (j % R == 0):
            mask[:, j] = 1
    return kspace * mask, mask

def sense_reconstruct(coil_images_folded, sens_maps, R):
    C, nx, ny = coil_images_folded.shape
    out = np.zeros((nx, ny), dtype=np.complex128)
    for i in range(nx):
        for j in range(ny//R):  # folded columns
            # indices of unfolded positions that fold to this folded col:
            cols = [j + k*(ny//R) for k in range(R)]
            # build S (C x R)
            S = np.zeros((C, R), dtype=np.complex128)
            d = np.zeros((C,), dtype=np.complex128)
            for c in range(C):
                # measurement = sum_k s_c(pos_k) * x(pos_k)
                S[c, :] = sens_maps[c, i, cols]
                d[c] = np.sum(coil_images_folded[c, i, j::(ny//R)])  
            Reg = 1e-3
            StS = S.conj().T @ S + Reg*np.eye(R)
            x_fold = np.linalg.solve(StS, S.conj().T @ d)
            # assign to out at the first unfolded pos (for visualization)
            out[i, cols[0]] = x_fold[0]
    return out

def main():
    nx = 128
    C = 8
    img = create_phantom(nx)
    sens = simulate_sensitivity_maps(nx, nx, C)  # C x nx x nx
    coil_images = sens * img[None, :, :]  
    coil_k = np.array([fft2c(coil_images[c]) for c in range(C)])
    R = 4
    coil_k_us, mask = undersample_kspace(coil_k, R)
    coil_images_folded = np.array([ifft2c(coil_k_us[c]) for c in range(C)])
    rec = sense_reconstruct(coil_images_folded, sens, R)
    plt.figure(figsize=(10,4))
    plt.subplot(1,3,1); plt.imshow(np.abs(img), cmap='gray'); plt.title("原图")
    plt.subplot(1,3,2); plt.imshow(np.abs(coil_images_folded[0]), cmap='gray'); plt.title("某线圈折叠图")
    plt.subplot(1,3,3); plt.imshow(np.abs(rec), cmap='gray'); plt.title("SENSE demo 重建（演示）")
    plt.show()

if __name__ == "__main__":
    main()
```

**注意**：上面`sense_reconstruct`是一个非常简化的演示版本，真正的 SENSE 实现需要仔细处理折叠索引、线圈噪声协方差、每个折叠位置的多像素求解并合理分配恢复结果（R个被折叠像素分别恢复到正确位置），以及边界条件与并行化。常用工具包如 `BART`、`Gadgetron`、`ISMRI` 提供成熟实现。

### 2.3 GRAPPA（k 空间插值）

GRAPPA在k空间中学习线性插值核，把已采样的邻域线圈数据线性组合成未采样点的估计。核心思想：

* 从自校正数据（ACS, fully-sampled k-space 中央区域）提取训练样本，学习线性系数 $W$
  
$$
  k_\text{target}(p) \approx \sum_{(c,\Delta k)} W_{c,\Delta k} , k_c(p + \Delta k)
$$

  其中 $c$ 表示线圈通道， $\Delta k$ 为邻域偏移。
* 用训练得到的系数 $W$ 对欠采样 $k$ 空间的缺失点进行插值。
* 插值后对每个线圈做iFFT得到coil图像，然后合成如根加权合并：RSS或进一步做SENSE风格的合成。

GRAPPA在工程上更稳定（不依赖显式敏感度 maps），且对ACS数据要求较高（需要合适大小的ACS）。

实现GRAPPA稍复杂需构造 Toeplitz 矩阵并做最小二乘，此处不贴出完整实现，但可说明常见步骤与参数（kernel 大小、ACS 大小、正则化 λ）。

### 2.4 并行成像注意事项与实践

①灵敏度估计：准确的敏感度map对SENSE关键。估计方法包括：单独采集的灵敏度扫描、ESPIRiT（自我校正并生成多组灵敏度基）、或基于coil图像的平滑/归一化。

②噪声协方差：线圈间不独立时需估计噪声协方差矩阵 $\Psi$ 并在合并过程中做加权。

③并行化与稳定性：当 $C$ 较小或 $R$ 较大， $S^H S$ 条件数差会导致噪声放大（g-factor）,g-factor 描述并行重建的噪声放大程度。

④自校准空间ACS大小：GRAPPA 需要足够的 ACS 区域以稳定地估计插值系数。

⑤混合方法：现代方法常把GRAPPA、SENSE与 CS、深度网结合，例如利用GRAPPA插值恢复k空间，再用 CS 优化/深度去伪影；或在 unrolled 网络中加入并行成像数据一致性项。

## 3 深度学习重建

### 3.1 概览与方法分支

近年来深度学习在 MRI 重建取得显著进展，方法大致分为几类：

1. 端到端监督学习：输入（零填充、低质量图）→ 网络 → 输出高质量图。常用 U-Net、ResNet 等。
2. 数据一致性嵌入：将经典迭代优化算法展开为可训练模块（每层包含去噪子网络 + 数据一致性步骤），如 MoDL、VN、ADMM-Net、ISTA-Net 等。
3. k空间学习（k-space、hybrid）：在 k 空间或混合域学习插值/补全例如 DeepGRAPPA、k-space U-Net。
4. 生成对抗网络（GAN）与感知损失：用于提升细节感知，减少模糊但可能引入假结构。
5. 半监督、无监督、自监督：通过数据自监督或保序性约束减少对成对干净标签的依赖（例如 SSDU、self-supervised learning）。
6. 物理可解释、变分网络：结合物理前向模型与学习的先验（如变分网络、MoDL），兼顾理论可解释性与性能。

### 3.2 关键思想：数据一致性

大多数最成功的方法在网络中嵌入数据一致性项，保证输出图像在k空间已采样点上与测量一致。常见做法：在每次迭代中把网络输出的k空间在采样mask位置替换为测量值（硬替换），或进行加权更新（软替换）。

### 3.3 代表模型简介

①U-Net：编码-解码结构，跳跃连接，适合图像去噪、重建。

②MoD：将正则化-数据一致性迭代化为可训练网络，每步使用 CNN 做正则化，然后做线性数据一致性（在k空间解线性方程）。

③VN：直接将变分优化展开的逐步更新作为网络模块。

④AUTOMAP：端到端直接把k空间映射到图像的全连接网络（参数巨大，适合小尺寸）。

⑤ADMM-Net\ISTA-Net：将经典迭代优化（ADMM、ISTA）进行“网络化”并在每步加入可训练模块。

⑥SSDU：分割已采样数据做自监督，减轻对fully-sampled labels依赖。

⑦Physics-guided deep learning：结合前向模型傅里叶、敏感度等与学习组件。

### 3.4 损失函数与评价

常用的损失函数有像素级 $L_1\L_2$ 损失（与标签重建差异）；结构相似性（SSIM）损失或感知损失（VGG 特征）；对抗损失（GAN）；组合损失（ $L_1$ + SSIM+感知）等方法。

评价指标：PSNR、SSIM、NMSE、视觉评估与临床指标例如病灶检测一致性。

### 3.5 数据准备与训练细节

①输入输出：输入常为零填充图像、低分辨率图像或多通道coil数据（含敏感度）。

②复杂数处理：处理复值数据有两种策略：把实部/虚部分别作为通道；或直接用复数神经网络（不常见）。很多实现使用两通道（real、imag）。

③数据增强：几何变换、仿真噪声、相位扰动。

④批量与patch：内存限制下用patch训练即把以整块图像分为几个小的部分以及小批次训练，减少单次训练过程中的显存消耗。

⑤归一化：常把图像按其 $l_2$ 范数或最大值归一化。

⑥学习率、优化器：Adam、SGD等常用学习率调度、early-stopping。

### 3.6 代码示例

下面示例演示输入为零填充图像复数两通道，网络为U-Net输出去噪图，再与k空间测量做数据一致性（替换采样点）。

```python
# 文件：unet_dc_recon.py
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import Dataset, DataLoader


# 工具函数：FFT / iFFT（torch）
def fft2c_torch(x):
    # x: B x 2 x H x W (real, imag)
    xr = x[:,0,:,:]
    xi = x[:,1,:,:]
    complex_x = torch.complex(xr, xi)
    k = torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(complex_x, dim=(-2,-1)), norm='ortho'), dim=(-2,-1))
    return torch.stack([k.real, k.imag], dim=1)

def ifft2c_torch(k):
    kr = k[:,0,:,:]
    ki = k[:,1,:,:]
    complex_k = torch.complex(kr, ki)
    x = torch.fft.fftshift(torch.fft.ifft2(torch.fft.ifftshift(complex_k, dim=(-2,-1)), norm='ortho'), dim=(-2,-1))
    return torch.stack([x.real, x.imag], dim=1)


# 简单 U-Net（两通道输入/输出）
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.ReLU(inplace=True),
        )
    def forward(self,x): return self.net(x)

class UNet2D(nn.Module):
    def __init__(self, in_ch=2, out_ch=2, base_ch=32):
        super().__init__()
        self.enc1 = DoubleConv(in_ch, base_ch)
        self.enc2 = DoubleConv(base_ch, base_ch*2)
        self.enc3 = DoubleConv(base_ch*2, base_ch*4)
        self.pool = nn.MaxPool2d(2)
        self.up2 = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, stride=2)
        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, stride=2)
        self.dec2 = DoubleConv(base_ch*4, base_ch*2)
        self.dec1 = DoubleConv(base_ch*2, base_ch)
        self.outc = nn.Conv2d(base_ch, out_ch, 1)
    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        d2 = self.up2(e3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)
        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)
        out = self.outc(d1)
        return out

# 简化数据集 Demo（合成数据）
class MRIDataset(Dataset):
    def __init__(self, imgs, mask):
        # imgs: N x H x W (real intensity images)
        self.imgs = imgs
        self.mask = mask
    def __len__(self): return len(self.imgs)
    def __getitem__(self, idx):
        img = self.imgs[idx]
        # generate kspace
        k = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(img)))
        # apply mask
        k_us = k * self.mask
        # zero-filled image
        zf = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(k_us)))
        # make two-channel real/imag
        zf_ch = np.stack([np.real(zf), np.imag(zf)], axis=0).astype(np.float32)
        img_ch = np.stack([np.real(img), np.imag(img)], axis=0).astype(np.float32)
        return torch.from_numpy(zf_ch), torch.from_numpy(img_ch), torch.from_numpy(np.stack([np.real(k_us), np.imag(k_us)], axis=0).astype(np.float32))

# 训练循环（简单）
def data_consistency(img_pred, k_meas, mask):
    # img_pred: B x 2 x H x W
    k_pred = fft2c_torch(img_pred)
    # enforce measured k-space at mask positions
    k_out = k_pred * (1 - mask) + k_meas * mask
    img_out = ifft2c_torch(k_out)
    return img_out

def train_demo():
    # 构造简单数据: 若干合成高斯图
    N = 50
    H = W = 128
    imgs = []
    for _ in range(N):
        X = np.linspace(-1,1,H)
        Y = np.linspace(-1,1,W)
        XX, YY = np.meshgrid(X,Y, indexing='ij')
        img = np.exp(-((XX - 0.2*np.random.randn())**2 + (YY - 0.2*np.random.randn())**2)/(0.02 + 0.01*np.random.rand()))
        imgs.append(img)
    imgs = np.array(imgs)
    # mask: variable density (简单)
    mask = np.zeros((H,W), dtype=np.float32)
    for j in range(W):
        if j % 4 == 0:
            mask[:, j] = 1.0
    mask = np.fft.fftshift(mask)
    mask_torch = torch.from_numpy(np.stack([mask, mask], axis=0)).unsqueeze(0).float() # Bx2xHxW compatible
    dataset = MRIDataset(imgs, mask)
    loader = DataLoader(dataset, batch_size=4, shuffle=True)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = UNet2D(in_ch=2, out_ch=2).to(device)
    opt = optim.Adam(model.parameters(), lr=1e-3)
    criterion = nn.L1Loss()
    for epoch in range(5):
        for zf, tgt, k_us in loader:
            zf = zf.to(device)
            tgt = tgt.to(device)
            # precompute mask and k_us in complex two-channel
            k_us = k_us.to(device)
            # forward
            pred = model(zf)
            # data consistency
            pred_dc = data_consistency(pred, k_us, mask_torch.to(device))
            loss = criterion(pred_dc, tgt)
            opt.zero_grad(); loss.backward(); opt.step()
        print(f"Epoch {epoch} loss {loss.item():.6f}")
    # 保存模型
    torch.save(model.state_dict(), "unet_dc_demo.pth")
    print("训练完成，模型保存在 unet_dc_demo.pth")

if __name__ == "__main__":
    train_demo()
```

要点分析：上述代码使用合成灰度图像、简化mask、并把数据一致性实现为“硬替换”（用mask直接替换k空间位置）。真实应用需要处理coil数据（多通道）、敏感度maps、复杂数处理、批量加载真实k-space数据如fastMRI数据集，并使用合适的归一化与扩充。MoDL或VN更先进：在每步用CNN做正则，再在数据一致性步骤里做线性求解通常采用预因式分解或共轭梯度方法。

### 3.7 进阶

* 复数神经网络：直接支持complex权重与激活函数，理论上更天然地处理MRI的复数数据。
* 自监督学习：把采样到的 k 空间划分为训练/验证子集，在网络训练中既不需要完整标签又能学习重建。
* 可解释性与保真性：监督学习可能生成伪结构，临床应用需谨慎验证（可加入数据一致性与物理模型约束以减轻风险）。
* 多对比、多通道联合重建：利用多个时间点或不同对比数据的冗余信息（低秩 + 深度）。

### 3.8 深度重建的实战要点

①数据准备是关键，最好有真实的fully-sampled数据作为标签；若无则采用自监督方法；
②评估不仅看 PSNR/SSIM，还要结合医学任务（可视化病灶、诊断可达性）；
③模型需保证数据一致性与物理约束，避免伪影/伪结构；
④训练时采样模式要与实际扫描模式一致（或增强采样变体以提高鲁棒性）。

## 4 参考文献
[1] Pruessmann, K. P., Weiger, M., Scheidegger, M. B., & Boesiger, P. (1999). SENSE: sensitivity encoding for fast MRI. Magnetic Resonance in Medicine. 

[2] Griswold, M. A., Jakob, P. M., Heidemann, R. M., Nittka, M., Jellus, V., Wang, J., ... & Haase, A. (2002). Generalized autocalibrating partially parallel acquisitions (GRAPPA). Magnetic Resonance in Medicine. 

[3] Lustig, M., Donoho, D., & Pauly, J. M. (2007). Sparse MRI: The application of compressed sensing for rapid MR imaging. Magnetic Resonance in Medicine. 

[4] Beck, A., & Teboulle, M. (2009). A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences.

[5] Aggarwal, H. K., Mani, M. P., & Jacob, M. (2019). MoDL: Model-Based Deep Learning Architecture for Inverse Problems. IEEE Transactions on Medical Imaging.

[6] Hammernik, K., Klatzer, T., Kobler, E., Recht, M. P., Sodickson, D. K., & Pock, T. (2018). Learning a variational network for reconstruction of accelerated MRI data. Magnetic Resonance in Medicine.

[7] Zhu, B., Liu, J. Z., Cauley, S. F., Rosen, B. R., & Rosen, M. S. (2018). Image reconstruction by domain-transform manifold learning (AUTOMAP).

[8] Knoll, F., Clason, C., Bredies, K., Uecker, M., & Sodickson, D. K. (2020). Deep-learning methods for parallel MRI reconstruction: A survey of the current approaches, trends and issues. IEEE Signal Processing Magazine

[9] Wang, G., Ye, J. C., Mueller, K., & Fessler, J. A. (2020). Image reconstruction is a new frontier of machine learning. IEEE Transactions on Medical Imaging.

[10] Uecker, M., Lai, P., Murphy, M. J., Virtue, P., Elad, M., Pauly, J. M., ... & Lindquist, M. (2014). ESPIRiT - An eigenvalue approach to autocalibrating parallel MRI: Where SENSE meets GRAPPA. Magnetic Resonance in Medicine.

[11] Eksioglu, A., Tsiouris, A. J., & Papadopoulou, O. (2019). Recent developments in MRI acceleration techniques and application in neuroimaging.

