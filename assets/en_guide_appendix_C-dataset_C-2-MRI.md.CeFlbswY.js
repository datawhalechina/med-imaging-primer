import{_ as e,o as t,c as i,ak as s}from"./chunks/framework.CGzjHEBf.js";const h=JSON.parse('{"title":"Appendix C-2 MRI Type Datasets","description":"Introduces MRI type datasets","frontmatter":{"title":"Appendix C-2 MRI Type Datasets","description":"Introduces MRI type datasets"},"headers":[],"relativePath":"en/guide/appendix/C-dataset/C-2-MRI.md","filePath":"en/guide/appendix/C-dataset/C-2-MRI.md"}'),r={name:"en/guide/appendix/C-dataset/C-2-MRI.md"};function n(o,a,l,d,c,u){return t(),i("div",null,[...a[0]||(a[0]=[s('<h1 id="appendix-c-2-mri-type-datasets" tabindex="-1">Appendix C-2: MRI Type Datasets <a class="header-anchor" href="#appendix-c-2-mri-type-datasets" aria-label="Permalink to “Appendix C-2: MRI Type Datasets”">​</a></h1><h1 id="_1-brats-brain-tumor-mri-segmentation-dataset" tabindex="-1">1. BraTS (Brain Tumor MRI Segmentation Dataset) <a class="header-anchor" href="#_1-brats-brain-tumor-mri-segmentation-dataset" aria-label="Permalink to “1. BraTS (Brain Tumor MRI Segmentation Dataset)”">​</a></h1><h2 id="_1-1-brats-introduction" tabindex="-1">1.1. BraTS Introduction <a class="header-anchor" href="#_1-1-brats-introduction" aria-label="Permalink to “1.1. BraTS Introduction”">​</a></h2><p><strong>BraTS (Brain Tumor Segmentation Challenge)</strong> is a multi-modal MRI segmentation dataset for brain gliomas continuously launched by MICCAI since 2012, and also one of the most important public benchmarks in medical image segmentation. Its data comes from multiple centers, providing unified preprocessing and fine expert annotations, used to evaluate tasks such as tumor detection, region segmentation, and survival prediction, widely applied in academic research and clinical auxiliary diagnosis method development.</p><h2 id="_1-2-brats-data-structure" tabindex="-1">1.2. BraTS Data Structure <a class="header-anchor" href="#_1-2-brats-data-structure" aria-label="Permalink to “1.2. BraTS Data Structure”">​</a></h2><p>Typical versions (such as BraTS 2018–2021) contain hundreds to thousands of cases, each providing four standardized MRI sequences (all in NIfTI format and already skull-stripped and spatially aligned):</p><ul><li><strong>T1, T1CE, T2, FLAIR</strong></li></ul><p>Annotations are three types of voxel-level tumor regions:</p><ul><li><strong>WT (Whole Tumor)</strong></li><li><strong>TC (Tumor Core)</strong></li><li><strong>ET (Enhancing Tumor)</strong></li></ul><p>Common scale examples: BraTS 2020 contains <strong>369 training + 125 validation + 166 test</strong> cases; BraTS 2021 expands to <strong>1500+ cases</strong>. Each case&#39;s data structure is stable, suitable for segmentation, classification, and prognostic modeling.</p><h2 id="_1-3-brats-download-methods" tabindex="-1">1.3. BraTS Download Methods <a class="header-anchor" href="#_1-3-brats-download-methods" aria-label="Permalink to “1.3. BraTS Download Methods”">​</a></h2><ul><li>Official website (entries for each year): <a href="https://www.med.upenn.edu/cbica/brats/" target="_blank" rel="noreferrer">https://www.med.upenn.edu/cbica/brats/</a></li><li>Kaggle mirror: <a href="https://www.kaggle.com/search?q=BRaTS+in%3Adatasets" target="_blank" rel="noreferrer">Search | Kaggle</a></li><li>Aistudio download (BraTS2015): <a href="https://aistudio.baidu.com/datasetdetail/26367" target="_blank" rel="noreferrer">https://aistudio.baidu.com/datasetdetail/26367</a></li></ul><h1 id="_2-oasis-open-access-series-of-imaging-studies" tabindex="-1">2. OASIS (Open Access Series of Imaging Studies) <a class="header-anchor" href="#_2-oasis-open-access-series-of-imaging-studies" aria-label="Permalink to “2. OASIS (Open Access Series of Imaging Studies)”">​</a></h1><h2 id="_2-1-oasis-introduction" tabindex="-1">2.1 OASIS Introduction <a class="header-anchor" href="#_2-1-oasis-introduction" aria-label="Permalink to “2.1 OASIS Introduction”">​</a></h2><p>OASIS is a brain imaging dataset series initiated by Washington University in St. Louis (WashU), aiming to provide free MRI, PET, clinical and cognitive data of populations including normal aging and cognitive decline (such as Alzheimer&#39;s disease) to the research community.<br> This series includes multiple subsets (OASIS-1, OASIS-2, OASIS-3, OASIS-4), covering cross-sectional and longitudinal, multi-modal imaging data, suitable for studying brain structure changes, aging, cognitive decline, imaging-clinical correlations, etc.</p><h2 id="_2-2-oasis-data-structure" tabindex="-1">2.2 OASIS Data Structure <a class="header-anchor" href="#_2-2-oasis-data-structure" aria-label="Permalink to “2.2 OASIS Data Structure”">​</a></h2><p>The following are the main structures and characteristics of each subset:</p><h3 id="oasis-1-cross-sectional" tabindex="-1"><strong>OASIS-1</strong> (Cross-sectional) <a class="header-anchor" href="#oasis-1-cross-sectional" aria-label="Permalink to “OASIS-1 (Cross-sectional)”">​</a></h3><ul><li>Contains <strong>416 subjects</strong> (ages 18-96 years) and 100 cases of mild to moderate Alzheimer&#39;s disease over 60 years old.</li><li>Each subject obtains 3 or 4 frames of T1-weighted MRI in one scan.</li><li>Data format is public, providing images, demographics, and cognitive scores.</li></ul><h3 id="oasis-2-longitudinal" tabindex="-1"><strong>OASIS-2</strong> (Longitudinal) <a class="header-anchor" href="#oasis-2-longitudinal" aria-label="Permalink to “OASIS-2 (Longitudinal)”">​</a></h3><ul><li>Contains <strong>150 participants</strong> (ages 60-96 years), with a total of <strong>373 scanning sessions</strong>.</li><li>Longitudinal design: each participant is scanned during two or more visits, with at least one-year interval.</li><li>Aims to study brain structure and cognitive status changes over time.</li></ul><h3 id="oasis-3-longitudinal-multimodal-neuroimaging" tabindex="-1"><strong>OASIS-3</strong> (Longitudinal Multimodal Neuroimaging) <a class="header-anchor" href="#oasis-3-longitudinal-multimodal-neuroimaging" aria-label="Permalink to “OASIS-3 (Longitudinal Multimodal Neuroimaging)”">​</a></h3><ul><li>Contains approximately <strong>1,378 participants</strong> (of which 755 are cognitively normal, 622 are at different stages of cognitive decline, ages approximately 42-95 years)</li><li>Contains <strong>2,842 MR sessions</strong> (including T1w, T2w, FLAIR, ASL, SWI, resting-state BOLD, DTI)</li><li>Contains <strong>2,157+ PET scans</strong> (such as AV45, FDG), as well as additional sub-projects such as &quot;OASIS-3_AV1451&quot; (Tau PET)</li><li>Provides rich multi-modal imaging + clinical + cognitive + biomarker data, important resource for aging and Alzheimer&#39;s research.</li></ul><h3 id="oasis-4-clinical-cohort" tabindex="-1"><strong>OASIS-4</strong> (Clinical Cohort) <a class="header-anchor" href="#oasis-4-clinical-cohort" aria-label="Permalink to “OASIS-4 (Clinical Cohort)”">​</a></h3><ul><li>Contains <strong>663 subjects</strong> (ages 21-94), mainly clinical population with memory impairment or dementia evaluation.</li><li>Unlike OASIS-3, it is an independent clinical cohort, not a continuation of OASIS-3.</li></ul><h3 id="common-features-data-format" tabindex="-1"><strong>Common Features &amp; Data Format</strong> <a class="header-anchor" href="#common-features-data-format" aria-label="Permalink to “Common Features &amp; Data Format”">​</a></h3><ul><li>All imaging data are de-identified.</li><li>Provide MRI raw data (usually in DICOM/NIfTI format) and processed structures (such as FreeSurfer segmentation).</li><li>Equipped with clinical/cognitive/demographic metadata, such as age, gender, MMSE or CDR scores.</li></ul><h2 id="_2-3-oasis-download-methods" tabindex="-1">2.3 OASIS Download Methods <a class="header-anchor" href="#_2-3-oasis-download-methods" aria-label="Permalink to “2.3 OASIS Download Methods”">​</a></h2><ul><li>Official homepage: <a href="https://sites.wustl.edu/oasisbrains/" target="_blank" rel="noreferrer">https://sites.wustl.edu/oasisbrains/</a> (lists OASIS-1, 2, 3, 4 data items)</li><li>Registration/application access: some subsets require account registration and data use agreement consent on XNAT or NITRC‑IR platforms.</li><li>kaggle: <a href="https://www.kaggle.com/search?q=OASIS+in%3Adatasets" target="_blank" rel="noreferrer">Search | Kaggle</a></li></ul><h1 id="_4-fastmri-accelerated-mri-reconstruction-dataset" tabindex="-1">4. fastMRI (Accelerated MRI Reconstruction Dataset) <a class="header-anchor" href="#_4-fastmri-accelerated-mri-reconstruction-dataset" aria-label="Permalink to “4. fastMRI (Accelerated MRI Reconstruction Dataset)”">​</a></h1><h2 id="_4-1-fastmri-introduction" tabindex="-1">4.1. fastMRI Introduction <a class="header-anchor" href="#_4-1-fastmri-introduction" aria-label="Permalink to “4.1. fastMRI Introduction”">​</a></h2><p>fastMRI is a public medical imaging dataset jointly launched by NYU Langone Health and Meta AI Research (formerly Facebook AI Research), aiming to explore <strong>accelerating MRI scans, reducing sampling time, and improving reconstruction quality</strong> through AI methods.<br> The dataset has raw k-space data + DICOM reconstructed images, involving multiple organs such as knee, brain, prostate, and breast. Due to its &quot;true original MRI measurements + multi-modal&quot; characteristics, it has profound influence in medical image reconstruction, compressed sampling, transfer learning, and cross-organ generalization research.</p><h2 id="_4-2-fastmri-data-structure" tabindex="-1">4.2. fastMRI Data Structure <a class="header-anchor" href="#_4-2-fastmri-data-structure" aria-label="Permalink to “4.2. fastMRI Data Structure”">​</a></h2><p>(1) Covered Organs and Modalities</p><ul><li>Knee MRI: Over ~1,500 fully sampled + 10,000 clinical DICOM images.</li><li>Brain MRI: Approximately 6,970 fully sampled (1.5 T / 3 T) including T1, T2, FLAIR and other sequences.</li><li>Prostate MRI: 312 cases of 3 T acquired axial T2 + DWI sequences.</li><li>Breast MRI: 300 cases of 3 T dynamic contrast-enhanced (DCE) MR, using radial k-space sampling.</li></ul><p>(2) Data Format and Annotations</p><ul><li>Provide <strong>raw k-space data</strong> (ISMRMRD or vendor-neutral format) + <strong>reconstructed DICOM/NIfTI images</strong>.</li><li>Have undergone de-identification processing (metadata protection/cleaning), each subset is applied for use according to protocol.</li><li>In terms of annotations: although main focus is reconstruction tasks, fastMRI+ subset has also been derived, containing expert bounding box annotations for knee/brain lesions.</li></ul><p>(3) Task Types</p><ul><li>Accelerated MRI reconstruction: Recover high-quality images under small k-space sampling.</li><li>Compressed sampling and reconstruction algorithm benchmarks: Provide standard evaluation metrics (such as PSNR, SSIM) to compare different methods.</li><li>Cross-organ transfer learning, model generalization, and weakly supervised learning (with fastMRI+ annotations)</li></ul><h2 id="_4-3-fastmri-download-methods" tabindex="-1">4.3. fastMRI Download Methods <a class="header-anchor" href="#_4-3-fastmri-download-methods" aria-label="Permalink to “4.3. fastMRI Download Methods”">​</a></h2><ul><li>Official homepage: <a href="https://fastmri.med.nyu.edu/" target="_blank" rel="noreferrer">https://fastmri.med.nyu.edu/</a></li><li>AWS open data storage: <a href="https://registry.opendata.aws/nyu-fastmri/" target="_blank" rel="noreferrer">https://registry.opendata.aws/nyu-fastmri/</a></li><li>GitHub code repository: <a href="https://github.com/facebookresearch/fastMRI" target="_blank" rel="noreferrer">https://github.com/facebookresearch/fastMRI</a> (including data loaders, baseline models)</li></ul><p><strong>Application Process</strong>:</p><ul><li>Need to agree to &quot;Data Sharing Agreement / Dataset Sharing Agreement&quot;</li><li>Fill in institution information, research purposes, etc.</li><li>Data is limited to &quot;research or teaching purposes&quot; and unauthorized redistribution is prohibited.</li></ul>',43)])])}const m=e(r,[["render",n]]);export{h as __pageData,m as default};
