import{_ as o,I as n,o as s,c as l,ak as i,J as t,j as r}from"./chunks/framework.CGzjHEBf.js";const y=JSON.parse('{"title":"2.3 X-ray: Direct Imaging Corrections","description":"Understand the preprocessing workflow for digital radiography (DR), including flat panel detector principles, core correction steps, and differences versus CT.","frontmatter":{"title":"2.3 X-ray: Direct Imaging Corrections","description":"Understand the preprocessing workflow for digital radiography (DR), including flat panel detector principles, core correction steps, and differences versus CT."},"headers":[],"relativePath":"en/guide/ch02/04-xray-preprocessing.md","filePath":"en/guide/ch02/04-xray-preprocessing.md"}'),c={name:"en/guide/ch02/04-xray-preprocessing.md"};function d(p,e,m,u,h,g){const a=n("Mermaid");return s(),l("div",null,[e[0]||(e[0]=i('<h1 id="_2-3-x-ray-direct-imaging-corrections" tabindex="-1">2.3 X-ray: Direct Imaging Corrections <a class="header-anchor" href="#_2-3-x-ray-direct-imaging-corrections" aria-label="Permalink to “2.3 X-ray: Direct Imaging Corrections”">​</a></h1><h2 id="introduction" tabindex="-1">Introduction <a class="header-anchor" href="#introduction" aria-label="Permalink to “Introduction”">​</a></h2><p>Unlike CT scanning, X-ray direct imaging (Digital Radiography, DR) is a projection imaging technique that acquires a 2D projection image with one or a few exposures. Modern X-ray systems predominantly use Flat Panel Detectors (FPDs). These offer high resolution and sensitivity, while introducing specific correction needs that must be addressed in preprocessing.</p><p>This chapter dives into the DR preprocessing workflow: detector working principles, detailed algorithms for each correction step, and key differences from CT preprocessing.</p><h3 id="core-questions" tabindex="-1">Core Questions <a class="header-anchor" href="#core-questions" aria-label="Permalink to “Core Questions”">​</a></h3><ol><li>How do X-ray flat panel detectors work? What are the pros and cons of different detector types?</li><li>What correction steps does DR require? What are the physical principles behind each?</li><li>How does DR preprocessing differ from CT? Why do they require different correction methods?</li></ol><div class="tip custom-block"><p class="custom-block-title">DR preprocessing matters</p><p>Image quality in DR directly depends on preprocessing. Incomplete corrections can cause artifacts, reduce contrast, and harm diagnostic accuracy.</p></div><hr><h2 id="x-ray-flat-panel-detectors-and-signal-acquisition" tabindex="-1">X-ray Flat Panel Detectors and Signal Acquisition <a class="header-anchor" href="#x-ray-flat-panel-detectors-and-signal-acquisition" aria-label="Permalink to “X-ray Flat Panel Detectors and Signal Acquisition”">​</a></h2><h3 id="basic-structure-of-fpds" tabindex="-1">Basic Structure of FPDs <a class="header-anchor" href="#basic-structure-of-fpds" aria-label="Permalink to “Basic Structure of FPDs”">​</a></h3><p>Modern DR adopts FPDs composed of an X-ray conversion layer, optical/electrical conversion layer, TFT pixel array, and readout electronics arranged as a 2D matrix. Typical pixel sizes are about 100–200 μm; arrays range from 1k×1k to 4k×4k, corresponding to a 200×200–400×400 mm field of view and real-time imaging at 30–60 fps.</p><div class="info custom-block"><p class="custom-block-title">Advantages of FPDs</p><p>Compared with film and image intensifiers, FPDs provide higher resolution, lower noise, larger dynamic range, and better real-time performance—dominant in current clinical practice.</p></div><h3 id="two-types-of-detectors" tabindex="-1">Two Types of Detectors <a class="header-anchor" href="#two-types-of-detectors" aria-label="Permalink to “Two Types of Detectors”">​</a></h3><h4 id="indirect-conversion-detectors-scintillator-based" tabindex="-1">Indirect Conversion Detectors (Scintillator-based) <a class="header-anchor" href="#indirect-conversion-detectors-scintillator-based" aria-label="Permalink to “Indirect Conversion Detectors (Scintillator-based)”">​</a></h4><p>CsI/CaWO₄ scintillator + a-Si photodiode + TFT: X-rays first convert to visible light in the scintillator; photodiodes then generate charge that is read out via TFTs. Typical detective quantum efficiency is ~60–80%; spatial resolution ~3–5 lp/mm; lower noise and cost, but light spread limits resolution and scintillator afterglow can introduce lag/ghosting.</p><h4 id="direct-conversion-detectors-photoconductor-based" tabindex="-1">Direct Conversion Detectors (Photoconductor-based) <a class="header-anchor" href="#direct-conversion-detectors-photoconductor-based" aria-label="Permalink to “Direct Conversion Detectors (Photoconductor-based)”">​</a></h4><p>~200–400 μm a-Se photoconductor + TFT: X-rays directly generate electron–hole pairs in a-Se; under an electric field they drift and are read out by TFTs. DQE can reach ~70–90%; spatial resolution ~5–7 lp/mm; no light spread and sharper imaging, but higher cost, greater temperature sensitivity, and more pronounced lag/charge accumulation issues.</p><h4 id="comparison" tabindex="-1">Comparison <a class="header-anchor" href="#comparison" aria-label="Permalink to “Comparison”">​</a></h4><ul><li>Quantum efficiency: Indirect 60–80% vs Direct 70–90%</li><li>Spatial resolution: Indirect 3–5 lp/mm vs Direct 5–7 lp/mm</li><li>Cost: Indirect lower vs Direct higher</li><li>Maturity: Indirect high vs Direct medium</li><li>Lag/ghosting: Indirect moderate vs Direct potentially more visible</li><li>Temperature sensitivity: Indirect low vs Direct high</li><li>Clinical application: Indirect widespread vs Direct in high-end systems</li></ul><hr><h2 id="dr-correction-workflow" tabindex="-1">DR Correction Workflow <a class="header-anchor" href="#dr-correction-workflow" aria-label="Permalink to “DR Correction Workflow”">​</a></h2><h3 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to “Overview”">​</a></h3>',22)),t(a,{id:"mermaid-7xvgcdyxh",code:`graph TD
    A[Raw Projection Data] --> B[Dark Field Correction]
    B --> C[Gain / Flat Field Correction]
    C --> D[Bad Pixel Correction]
    D --> E[Scatter Correction]
    E --> F[Lag (Ghosting) Correction]
    F --> G[Geometric Distortion Correction]
    G --> H[Corrected Projection Data]`}),e[1]||(e[1]=i('<div class="tip custom-block"><p class="custom-block-title">Ordering matters</p><p>Dark correction must come first—subsequent steps rely on a correct dark baseline. Gain correction then normalizes pixel response before downstream operations.</p></div><hr><h3 id="dark-field-correction" tabindex="-1">Dark Field Correction <a class="header-anchor" href="#dark-field-correction" aria-label="Permalink to “Dark Field Correction”">​</a></h3><p>Principle: Even with no X-ray exposure, the detector produces a dark signal components from thermal noise, leakage current, electronics noise, and TFT characteristics. If not removed, this forms fixed-pattern noise.</p><p>Algorithm for pixel i:</p><ol><li>Acquire dark references under no X-ray exposure: N_dark frames (typically 10–100)</li><li>Dark mean: I_dark,i = (1/N_dark) Σ_k I_dark,i^(k)</li><li>Dark standard deviation (for QC): σ_dark,i = sqrt((1/N_dark) Σ_k (I_dark,i^(k) − I_dark,i)^2)</li><li>Apply correction: I_corrected,i = I_measured,i − I_dark,i</li></ol><p>QC:</p><ul><li>σ_dark,i typically &lt; 1% of mean dark; dark values in reasonable ADU range; spatially smooth distribution</li><li>Update dark template regularly with time/temperature/aging (e.g., daily or post power-up)</li></ul><div class="warning custom-block"><p class="custom-block-title">Dark correction is fundamental</p><p>Insufficient dark subtraction leaves fixed noise patterns across all images; later steps cannot fully remove this baseline.</p></div><hr><h3 id="gain-flat-field-correction" tabindex="-1">Gain / Flat-Field Correction <a class="header-anchor" href="#gain-flat-field-correction" aria-label="Permalink to “Gain / Flat-Field Correction”">​</a></h3><p>Principle: Due to manufacturing tolerances and non-uniform beam profiles, pixels respond slightly differently under the same exposure. Gain correction uses a flat-field reference to normalize pixel responses.</p><p>Algorithm:</p><ol><li>Acquire flat-field references: N_flat frames under uniform exposure (conditions close to clinical use)</li><li>Flat mean: I_flat,i = (1/N_flat) Σ_k I_flat,i^(k)</li><li>Reference intensity (global median or mean): I_ref = median(I_flat,i) or I_ref = (1/N_pixel) Σ_i I_flat,i</li><li>Gain coefficient and correction: G_i = I_ref / I_flat,i I_corrected,i = (I_measured,i − I_dark,i) × G_i</li></ol><p>QC:</p><ul><li>Most G_i concentrated in 0.9–1.1; std &lt; 5%; spatially smooth</li><li>To compensate tube heel effect, modern systems use position-dependent G_i or multiple kVp-specific gain templates</li></ul><div class="tip custom-block"><p class="custom-block-title">Practical QC</p><p>Flat-field images not only build gain templates but also monitor large-area nonuniformity to detect hardware issues early.</p></div><hr><h3 id="bad-pixel-correction" tabindex="-1">Bad Pixel Correction <a class="header-anchor" href="#bad-pixel-correction" aria-label="Permalink to “Bad Pixel Correction”">​</a></h3><p>Principle: Manufacturing defects or wear introduce abnormal pixels: dead (always 0), hot (abnormally high), stuck (fixed value), noisy (very high variance). If unhandled, these produce bright/dark spots and local artifacts.</p><p>Detection strategies:</p><ul><li>Gain-based: if G_i &lt; 0.5 or G_i &gt; 2.0, flag pixel i (thresholds system-dependent)</li><li>Dark noise-based: σ_dark,i &gt; 3 × median(σ_dark) indicates abnormally high noise</li><li>Flat-field stability-based: Var(I_flat,i) &gt; 3 × median(Var(I_flat)) indicates instability</li></ul><p>Correction (interpolation):</p>',23)),e[2]||(e[2]=r("ul",null,[r("li",null,"Neighborhood mean: I_corrected,i = (1/N_neighbors) Σ_{j∈neighbors} I_corrected,j (4/8-neighborhood)"),r("li",null,"Weighted interpolation: I_corrected,i = (Σ_j w_j I_corrected,j) / (Σ_j w_j), with w_j = 1/d_ij^2"),r("li",{"i+1,j+1":""},"Bilinear interpolation (on regular grids): I_corrected,i,j = (1−α)(1−β) I_{i,j} + α(1−β) I_{i+1,j} + (1−α)β I_{i,j+1} + αβ I_")],-1)),e[3]||(e[3]=i('<p>QC:</p><ul><li>Total bad pixels &lt; 0.1% of all pixels; avoid clustered distribution</li><li>Corrected regions’ intensity and noise should match surroundings</li><li>Track bad pixel count over time; rapid growth suggests maintenance</li></ul><div class="info custom-block"><p class="custom-block-title">Practice</p><p>Factory calibration initializes bad pixel maps; clinics recheck weekly/monthly. Some high-end systems explore deep learning as an alternative to threshold+interpolation to better preserve diagnostic detail.</p></div><hr><h3 id="scatter-correction" tabindex="-1">Scatter Correction <a class="header-anchor" href="#scatter-correction" aria-label="Permalink to “Scatter Correction”">​</a></h3><p>Principle: Compton-scattered photons in the patient are still detected, elevating measured projection values, reducing contrast, and producing streaks. Simplified as:</p><p>p_measured = p_true + p_scatter</p><p>Goal: estimate p_scatter and subtract without increasing dose unduly.</p><p>Hardware: anti-scatter grid (lead strips + interspaces) to suppress scatter. Typical parameters: strip pitch ~1–2 mm, grid ratio 12:1–16:1, focal distance 100–150 cm. Performance: scatter rejection ~60–80%; primary transmission 70–85%; exposure factor ~1.2–1.5.</p><p>Software: estimate a smooth scatter field p_scatter(x,y) via small-aperture collimation measurement, patient-geometry-based Monte Carlo, or CNNs:</p><p>p_scatter(x,y) = f(patient geometry, X-ray spectrum, x, y)</p><p>Subtract in projection domain:</p><p>p_corrected(x,y) = p_measured(x,y) − p_scatter(x,y)</p><p>To avoid overcorrection, use a weight α and truncation:</p><p>p_corrected(x,y) = max(p_measured(x,y) − α · p_scatter(x,y), 0)</p><p>Typical α in 0.5–1.0 depending on system and noise.</p><p>Method comparison:</p><ul><li>Anti-scatter grid: 60–80% scatter removal; ~0 ms compute; low complexity; standard DR</li><li>Small-aperture collimation: 70–90%; 100–500 ms; medium complexity; high-precision use</li><li>Monte Carlo: 80–95%; 1–10 s; high complexity; research/special cases</li><li>Machine learning: 85–95%; &lt;100 ms; high complexity; real-time use</li></ul><div class="warning custom-block"><p class="custom-block-title">Challenges</p><p>Scatter depends on body habitus, field size, kVp, etc. Excessive α or model bias amplifies noise or yields negative projections. Clinical systems cap correction strength and tune via phantom experiments.</p></div><hr><h3 id="lag-ghosting-correction" tabindex="-1">Lag (Ghosting) Correction <a class="header-anchor" href="#lag-ghosting-correction" aria-label="Permalink to “Lag (Ghosting) Correction”">​</a></h3><p>Principle: Lag refers to residual signal from a prior frame carrying over to subsequent frames—seen as faint ghosting behind moving structures. Sources include scintillator afterglow (CsI: ~μs), a-Se charge traps (ms-scale release), TFT charge/discharge, and readout residual integration.</p><p>Typical characteristics:</p><ul><li>Ghosting behind fast motion</li><li>Time dependence: prominent in fluoroscopy</li><li>Residual amplitude: typically 1–5% of prior frame, affecting multiple frames</li></ul><p>Models:</p><ul><li>First-order lag: I_lag^(n) = α · I_measured^(n−1)</li><li>Second-order lag: I_lag^(n) = α · I_measured^(n−1) + β · I_lag^(n−1) (α ≈ 0.01–0.05; β ≈ 0.1–0.3)</li><li>Multi-order: I_lag^(n) = Σ_{k=1}^K α_k · I_measured^(n−k) (K typically 2–5)</li></ul><p>Measurement and correction via alternating black/white frames:</p><ol><li>Acquire black frames (no X-ray): I_black^(n)</li><li>Acquire white frames (max X-ray): I_white^(n)</li><li>Alternate acquisition; residual in black frames: I_residual^(n) = I_black^(n) − I_dark</li><li>First-order parameter: α = I_residual^(n) / I_white^(n−1)</li></ol><p>Then subtract modeled lag: I_corrected^(n) = I_measured^(n) − I_lag^(n)</p><p>QC:</p><ul><li>α &lt; 5%; otherwise recalibrate or inspect detector</li><li>Residual ghosting &lt; 1% after correction; fluoroscopy contrast improves ~10–20%</li><li>Do not significantly degrade temporal resolution</li></ul><div class="warning custom-block"><p class="custom-block-title">Practical notes</p><p>Cardiovascular fluoroscopy exhibits strong lag, but precise modeling is difficult. Besides software, high-end systems reduce lag via fast reset circuits, forward biasing of a-Se, and multi-sampling.</p></div><hr><h3 id="geometric-distortion-correction" tabindex="-1">Geometric Distortion Correction <a class="header-anchor" href="#geometric-distortion-correction" aria-label="Permalink to “Geometric Distortion Correction”">​</a></h3><p>Principle: Due to point-source geometry and detector configuration, projections may exhibit barrel/pincushion distortion, radial shift, and tangential skew. Causes include source misalignment, detector tilt, optical nonlinearity, and temperature-induced mechanical deformation. Quantitative measurement/navigation requires correction.</p><p>Calibration and modeling:</p><ol><li>Capture calibration images using checkerboards, dot arrays, or line targets uniformly across the FOV</li><li>Detect marker positions (edges/corners/circles) to obtain measured coordinates (x_measured, y_measured) and pair with ideal coordinates (x_ideal, y_ideal)</li><li>Position deviations: Δx = x_measured − x_ideal; Δy = y_measured − y_ideal</li></ol><p>Fit distortion model from deviations:</p><ul><li>Radial distortion: r_corr = r_meas (1 + k1 r_meas^2 + k2 r_meas^4 + k3 r_meas^6 + …) where r_meas = sqrt((x_meas − x_c)^2 + (y_meas − y_c)^2)</li><li>Tangential distortion: x_corr = x_meas + (p1 (r^2 + 2 x_meas^2) + 2 p2 x_meas y_meas) y_corr = y_meas + (p2 (r^2 + 2 y_meas^2) + 2 p1 x_meas y_meas)</li></ul><p>Parameters are typically fitted via least squares minimizing Σ_i (Δx_i^2 + Δy_i^2). Using 20–50 well-distributed markers provides sufficient accuracy.</p><p>Resampling and QC:</p><p>For each pixel (x, y), compute corrected position (x_corr, y_corr), then interpolate (nearest, bilinear, bicubic). Clinical systems often use bilinear interpolation for speed/quality balance.</p><p>QC:</p><ul><li>Post-correction grid lines near ideal straightness; residual distortion &lt; 0.5 pixel</li><li>MTF change &lt; 5%; avoid resolution loss</li><li>For quantitative apps (BMD, surgical planning), recalibrate monthly</li></ul><div class="tip custom-block"><p class="custom-block-title">Importance</p><p>In applications requiring precise measurement (e.g., bone densitometry, surgical navigation), geometric correction is critical—uncorrected distortion causes measurement and localization errors.</p></div><hr><h2 id="differences-between-dr-and-ct-preprocessing" tabindex="-1">Differences Between DR and CT Preprocessing <a class="header-anchor" href="#differences-between-dr-and-ct-preprocessing" aria-label="Permalink to “Differences Between DR and CT Preprocessing”">​</a></h2><h3 id="geometry-and-acquisition" tabindex="-1">Geometry and Acquisition <a class="header-anchor" href="#geometry-and-acquisition" aria-label="Permalink to “Geometry and Acquisition”">​</a></h3><ul><li>Projection geometry: DR uses parallel/point-source projection; CT uses fan/ cone-beam</li><li>Acquisition: DR single/few exposures; CT rotational multi-angle projections</li><li>Detector: DR uses 2D FPD; CT uses 1D or 2D arrays</li><li>Data volume: DR small; CT large</li><li>Temporal resolution: DR high (real time); CT lower (rotation required)</li><li>Spatial resolution: DR high (2D); CT moderate (3D)</li><li>Contrast resolution: DR lower (single projection); CT higher (multi-angle averaging)</li></ul><h3 id="workflow-comparison" tabindex="-1">Workflow Comparison <a class="header-anchor" href="#workflow-comparison" aria-label="Permalink to “Workflow Comparison”">​</a></h3><p>Common steps: dark, gain, bad pixel, scatter corrections.</p><p>DR-specific: lag correction; geometric distortion correction.</p><p>CT-specific: air calibration; beam hardening correction; ring artifact correction.</p><p>Order:</p><p>DR: Dark → Gain → Bad Pixel → Scatter → Lag → Geometric</p><p>CT: Dark → Gain → Air → Beam Hardening → Scatter → Ring Artifact</p><h3 id="parameter-differences" tabindex="-1">Parameter Differences <a class="header-anchor" href="#parameter-differences" aria-label="Permalink to “Parameter Differences”">​</a></h3><ul><li>Dark reference: no exposure for both</li><li>Gain reference: uniform exposure for both</li><li>Air calibration: DR not needed; CT needed (no object projection)</li><li>Lag coefficient: 1–5% in DR; N/A in CT</li><li>Geometric distortion: DR requires correction; CT usually compensated by rotation geometry</li><li>Beam hardening: DR not needed (single projection); CT needed (polyenergetic beam through multiple angles)</li><li>Ring artifacts: DR N/A; CT needed</li></ul><h3 id="complexity-and-timing" tabindex="-1">Complexity and Timing <a class="header-anchor" href="#complexity-and-timing" aria-label="Permalink to “Complexity and Timing”">​</a></h3><p>DR preprocessing is mostly per-pixel, simpler and faster—supports real-time per-frame processing. CT preprocessing must consider projection geometry and polychromatic physics; computation is heavier and often offline/batch, emphasizing inter-angle consistency and beam hardening model accuracy.</p><p>Timing reference (indicative):</p><ul><li>Dark/Gain/Bad pixel: &lt;1 ms each (per frame)</li><li>Scatter: 1–100 ms (DR) vs 100–1000 ms (CT)</li><li>Lag: &lt;1 ms (DR) vs N/A (CT)</li><li>Geometric distortion: 10–50 ms (DR) vs N/A (CT)</li></ul><hr><h2 id="data-flow-and-quality-control" tabindex="-1">Data Flow and Quality Control <a class="header-anchor" href="#data-flow-and-quality-control" aria-label="Permalink to “Data Flow and Quality Control”">​</a></h2><h3 id="complete-preprocessing-flow" tabindex="-1">Complete Preprocessing Flow <a class="header-anchor" href="#complete-preprocessing-flow" aria-label="Permalink to “Complete Preprocessing Flow”">​</a></h3>',65)),t(a,{id:"mermaid-9xoexcupj",code:`graph LR
    A[Raw Projection] --> B[Dark]
    B --> C[Gain]
    C --> D[Bad Pixel]
    D --> E[Scatter]
    E --> F[Lag]
    F --> G[Geometric]
    G --> H[Corrected Projection]
    H --> I[Quality Assessment]
    I --> J{Pass?}
    J -->|Yes| K[To Reconstruction]
    J -->|No| L[Re-acquisition]`}),e[4]||(e[4]=i('<h3 id="qc-indicators" tabindex="-1">QC Indicators <a class="header-anchor" href="#qc-indicators" aria-label="Permalink to “QC Indicators”">​</a></h3><ul><li>Projection data: SNR &gt; 50 dB; CNR &gt; 10; utilize 12–16 bit dynamic range; artifact level &lt; ~5% of image intensity</li><li>Post-correction: dark residual &lt; 1%; gain nonuniformity &lt; 5%; bad pixel ratio &lt; 0.1%; geometric error &lt; 0.5 pixel</li></ul><div class="tip custom-block"><p class="custom-block-title">QC cadence</p><p>Routine QC detects system issues early. Clinically, adopt “daily quick checks + weekly detailed evaluation.”</p></div><hr><h2 id="summary-and-next-steps" tabindex="-1">Summary and Next Steps <a class="header-anchor" href="#summary-and-next-steps" aria-label="Permalink to “Summary and Next Steps”">​</a></h2><p>This chapter covered FPD types and principles, and systematically introduced dark, gain, bad pixel, scatter, lag, and geometric distortion corrections with math and implementation ideas, plus key QC metrics.</p><p>Compared to CT’s multi-angle projections and unique issues (beam hardening, ring artifacts), DR emphasizes pixel-level uniformity, lag, and geometric control in single-projection imaging—prioritizing 2D real-time stability.</p><p>Calibrated projections proceed to Chapter 3 (reconstruction). Different projection geometries (parallel, fan, cone) map to different algorithms; understanding preprocessing and geometry here benefits subsequent learning.</p><div class="info custom-block"><p class="custom-block-title">Next</p><p>Before reconstruction, revisit Chapter 1’s projection geometry and this chapter’s data flow—consider how they jointly determine image quality.</p></div>',9))])}const b=o(c,[["render",d]]);export{y as __pageData,b as default};
