import{_ as a,o as t,c as i,ak as r}from"./chunks/framework.CGzjHEBf.js";const p=JSON.parse('{"title":"Appendix C-3 X-ray Type Datasets","description":"Introduces X-ray type datasets","frontmatter":{"title":"Appendix C-3 X-ray Type Datasets","description":"Introduces X-ray type datasets"},"headers":[],"relativePath":"en/guide/appendix/C-dataset/C-3-X-ray.md","filePath":"en/guide/appendix/C-dataset/C-3-X-ray.md"}'),s={name:"en/guide/appendix/C-dataset/C-3-X-ray.md"};function o(n,e,l,c,d,h){return t(),i("div",null,[...e[0]||(e[0]=[r('<h1 id="appendix-c-3-x-ray-type-datasets" tabindex="-1">Appendix C-3: X-ray Type Datasets <a class="header-anchor" href="#appendix-c-3-x-ray-type-datasets" aria-label="Permalink to “Appendix C-3: X-ray Type Datasets”">​</a></h1><h1 id="_3-chexpert-large-scale-chest-x-ray-lesion-detection-dataset" tabindex="-1">3. CheXpert (Large-scale Chest X-ray Lesion Detection Dataset) <a class="header-anchor" href="#_3-chexpert-large-scale-chest-x-ray-lesion-detection-dataset" aria-label="Permalink to “3. CheXpert (Large-scale Chest X-ray Lesion Detection Dataset)”">​</a></h1><h2 id="_3-1-chexpert-introduction" tabindex="-1">3.1. CheXpert Introduction <a class="header-anchor" href="#_3-1-chexpert-introduction" aria-label="Permalink to “3.1. CheXpert Introduction”">​</a></h2><p>CheXpert is a public chest X-ray image dataset released by Stanford University Medical Imaging and AI Team in 2019, mainly used for multi-label prediction of chest diseases (such as pneumonia, pleural effusion, cardiomegaly, etc.). The dataset is collected from real clinical scenarios, emphasizing the handling of uncertain (uncertainty) labels, and is widely used as a benchmark for chest X-ray AI research.</p><h2 id="_3-2-chexpert-data-structure" tabindex="-1">3.2. CheXpert Data Structure <a class="header-anchor" href="#_3-2-chexpert-data-structure" aria-label="Permalink to “3.2. CheXpert Data Structure”">​</a></h2><ul><li>Contains <strong>224,316 chest X-ray images</strong>, from <strong>65,240 patients</strong>, with time range approximately from October 2002 to July 2017.</li><li>Each image is accompanied by corresponding radiology reports, and <strong>14 observations</strong> are automatically extracted from the reports, with labels divided into three categories: &quot;positive (1)&quot;, &quot;negative (0)&quot;, and &quot;uncertain (-1/u)&quot;.</li><li>The 14 observations include: atelectasis (肺不张), cardiomegaly (心脏扩大), consolidation (实变), edema (水肿), enlarged cardiomediastinum, fracture, lung lesion, lung opacity, pleural effusion, pleural other, pneumonia, pneumothorax, support devices, no finding.</li><li>Data perspective: When there are multiple views (such as frontal + lateral), the model usually takes the maximum value of each view&#39;s prediction as the indicator.</li><li>Data division: Official provides training set + validation set; the test set consists of 500 independent studies, annotated by five certified radiologists as reference standard.</li></ul><h2 id="_3-3-chexpert-download-methods" tabindex="-1">3.3. CheXpert Download Methods <a class="header-anchor" href="#_3-3-chexpert-download-methods" aria-label="Permalink to “3.3. CheXpert Download Methods”">​</a></h2><ul><li>Official homepage: <a href="https://stanfordmlgroup.github.io/competitions/chexpert/" target="_blank" rel="noreferrer">https://stanfordmlgroup.github.io/competitions/chexpert/</a></li><li>Access conditions: Usually need to register an account and agree to the Research Use Agreement (RUA) before downloading data.</li><li>Kaggle mirror (such as &quot;CheXpert-v1.0-small&quot;) can also be accessed as a subset. <a href="https://www.kaggle.com/datasets/ashery/chexpert" target="_blank" rel="noreferrer">https://www.kaggle.com/datasets/ashery/chexpert</a></li></ul><h1 id="_2-mimic-cxr-large-scale-chest-x-ray-public-dataset" tabindex="-1">2. MIMIC-CXR (Large-scale Chest X-ray Public Dataset) <a class="header-anchor" href="#_2-mimic-cxr-large-scale-chest-x-ray-public-dataset" aria-label="Permalink to “2. MIMIC-CXR (Large-scale Chest X-ray Public Dataset)”">​</a></h1><h2 id="_2-1-mimic-cxr-introduction" tabindex="-1">2.1 MIMIC-CXR Introduction <a class="header-anchor" href="#_2-1-mimic-cxr-introduction" aria-label="Permalink to “2.1 MIMIC-CXR Introduction”">​</a></h2><p>MIMIC-CXR is a <strong>de-identified chest X-ray (chest radiograph) dataset</strong> collected by Beth Israel Deaconess Medical Center (BIDMC) in Boston and organized and made public by MIT Laboratory for Computational Physiology and other units. It contains hundreds of thousands of real clinical chest X-ray images matched with radiology reports, oriented toward image understanding, natural language processing, and decision support research.<br> For example, its first version is described as: covering approximately 65,379 patients from 2011-2016 period, 227,835 imaging examinations, and 377,110 images.<br> This dataset is considered an important benchmark for chest X-ray AI research due to its large scale, clear structure, and accompanying reports.</p><h2 id="_2-2-mimic-cxr-data-structure" tabindex="-1">2.2 MIMIC-CXR Data Structure <a class="header-anchor" href="#_2-2-mimic-cxr-data-structure" aria-label="Permalink to “2.2 MIMIC-CXR Data Structure”">​</a></h2><ul><li><strong>Image Quantity</strong>: Approximately 377,110 chest X-rays, associated with approximately 227,835 imaging examinations.</li><li><strong>Patient Quantity</strong>: Approximately 65,379 people.</li><li><strong>View Types</strong>: Most examinations include frontal and lateral views.</li><li><strong>Image Format</strong>: Provides DICOM format original images (de-identified) and corresponding report text.</li><li><strong>Report Text</strong>: Each examination is accompanied by free-text reports written by radiologists, describing imaging findings</li><li><strong>Data Annotation/Derivation</strong>: Users can extract structured labels (such as lesion presence, device location, etc.) based on report text for classification tasks.</li><li><strong>Task Types</strong>: Including chest X-ray abnormal detection/classification, radiology report-image pairing, image-text joint modeling.</li><li><strong>Usage Agreement</strong>: Data has undergone de-identification processing, complying with HIPAA Safe Harbour requirements.</li></ul><h2 id="_2-3-mimic-cxr-download-methods" tabindex="-1">2.3 MIMIC-CXR Download Methods <a class="header-anchor" href="#_2-3-mimic-cxr-download-methods" aria-label="Permalink to “2.3 MIMIC-CXR Download Methods”">​</a></h2><ul><li>Official hosting platform: <a href="https://physionet.org/content/mimic-cxr/2.1.0/" target="_blank" rel="noreferrer">https://physionet.org/content/mimic-cxr/2.1.0/</a></li><li>Download process usually includes: register account → sign data use agreement (Data Use Agreement, DUA) → approval → download.</li></ul><h1 id="_3-nih-chestx-ray14-chest-x-ray-multi-label-public-dataset" tabindex="-1">3. NIH ChestX-ray14 (Chest X-ray Multi-label Public Dataset) <a class="header-anchor" href="#_3-nih-chestx-ray14-chest-x-ray-multi-label-public-dataset" aria-label="Permalink to “3. NIH ChestX-ray14 (Chest X-ray Multi-label Public Dataset)”">​</a></h1><h2 id="_3-1-introduction" tabindex="-1">3.1 Introduction <a class="header-anchor" href="#_3-1-introduction" aria-label="Permalink to “3.1 Introduction”">​</a></h2><p>NIH ChestX-ray14 is a public chest X-ray image dataset released by the US National Institutes of Health (NIH) Clinical Center, initially released in 2017 under the name &quot;ChestX-ray8&quot;, and later expanded to include 14 types of common chest lesions (ChestX-ray14). This dataset contains over 100,000 clinical chest X-rays, accompanied by multi-labels automatically mined from text, and is widely used for chest X-ray classification, detection, and weakly supervised learning research.</p><h2 id="_3-2-data-structure" tabindex="-1">3.2 Data Structure <a class="header-anchor" href="#_3-2-data-structure" aria-label="Permalink to “3.2 Data Structure”">​</a></h2><ul><li>Image count: Approximately <strong>112,120 frontal chest X-rays</strong>, from <strong>30,805 unique patients</strong>.</li><li>Labels: Each image is accompanied by up to 14 chest lesion labels + &quot;No Finding&quot; category; labels are extracted from radiology reports using NLP.</li><li>Multi-label task: Each image may contain multiple lesions simultaneously (for example, edema + lung infiltration + cardiomegaly) → belonging to multi-label classification situation.</li><li>Image format: PNG format (some DICOM versions are accessible in Google Cloud)</li><li>Data division: Training set 86,524 images, test set 25,596 images.</li><li>Common tasks: Chest disease classification, weakly supervised localization (few annotated bounding boxes), multi-label metrics (ROC-AUC) evaluation.</li></ul><h2 id="_3-3-download-methods" tabindex="-1">3.3 Download Methods <a class="header-anchor" href="#_3-3-download-methods" aria-label="Permalink to “3.3 Download Methods”">​</a></h2><ul><li>Official download page: Box link provided by NIH Clinical Center <a href="https://nihcc.app.box.com/v/ChestXray-NIHCC" target="_blank" rel="noreferrer">https://nihcc.app.box.com/v/ChestXray-NIHCC</a></li><li>Google Cloud public storage bucket: <a href="https://docs.cloud.google.com/healthcare-api/docs/resources/public-datasets/nih-chest?hl=zh-cn" target="_blank" rel="noreferrer">https://docs.cloud.google.com/healthcare-api/docs/resources/public-datasets/nih-chest?hl=zh-cn</a></li><li>Kaggle mirror version: Such as &quot;NIH-Chest-X-rays&quot; is provided on Kaggle. <a href="https://www.kaggle.com/datasets/nih-chest-xrays/data" target="_blank" rel="noreferrer">https://www.kaggle.com/datasets/nih-chest-xrays/data</a></li><li>Usage notes: No payment required, no obvious usage restrictions, but requires indicating data source and citing the original paper.</li></ul>',22)])])}const m=a(s,[["render",o]]);export{p as __pageData,m as default};
