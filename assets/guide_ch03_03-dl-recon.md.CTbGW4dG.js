import{_ as a,o as l,c as r,ak as n}from"./chunks/framework.CGzjHEBf.js";const u=JSON.parse('{"title":"3.3 深度学习重建（AI4Recon）简介","description":"从后处理到可学习迭代：深度学习在重建中的典型范式与挑战","frontmatter":{"title":"3.3 深度学习重建（AI4Recon）简介","description":"从后处理到可学习迭代：深度学习在重建中的典型范式与挑战"},"headers":[],"relativePath":"guide/ch03/03-dl-recon.md","filePath":"zh/guide/ch03/03-dl-recon.md"}'),i={name:"guide/ch03/03-dl-recon.md"};function o(t,e,d,c,s,h){return l(),r("div",null,[...e[0]||(e[0]=[n('<h1 id="_3-3-深度学习重建-ai4recon-简介" tabindex="-1">3.3 深度学习重建（AI4Recon）简介 <a class="header-anchor" href="#_3-3-深度学习重建-ai4recon-简介" aria-label="Permalink to “3.3 深度学习重建（AI4Recon）简介”">​</a></h1><p>深度学习重建（AI for Reconstruction）可以看作：在“解析/迭代”两条主线之上，引入可学习模块以提升低剂量/稀疏采样场景的质量、速度与鲁棒性。</p><hr><h2 id="_1-三类典型范式" tabindex="-1">1. 三类典型范式 <a class="header-anchor" href="#_1-三类典型范式" aria-label="Permalink to “1. 三类典型范式”">​</a></h2><h3 id="_1-1-后处理-post-processing" tabindex="-1">1.1 后处理（post-processing） <a class="header-anchor" href="#_1-1-后处理-post-processing" aria-label="Permalink to “1.1 后处理（post-processing）”">​</a></h3><p>先用 FBP/FDK/FFT 得到初始图像，再用 CNN/Transformer 去噪、去伪影、做超分辨率等。</p><p>代表思路：</p><ul><li>FBPConvNet：FBP + CNN 后处理</li><li>RED-CNN：低剂量 CT 去噪</li><li>GAN/扩散：重建质量增强（需谨慎评估“幻觉”风险）</li></ul><h3 id="_1-2-可学习迭代-unrolling-unfolded-reconstruction" tabindex="-1">1.2 可学习迭代（unrolling / unfolded reconstruction） <a class="header-anchor" href="#_1-2-可学习迭代-unrolling-unfolded-reconstruction" aria-label="Permalink to “1.2 可学习迭代（unrolling / unfolded reconstruction）”">​</a></h3><p>把传统优化算法（如 ADMM、Primal-Dual）展开成网络结构，让其中的步长/正则项/近端算子变成可学习模块。</p><p>代表思路：</p><ul><li>Learned Primal-Dual</li><li>ADMM-Net</li><li>MoDL（模型驱动深度网络）</li></ul><h3 id="_1-3-端到端-end-to-end" tabindex="-1">1.3 端到端（end-to-end） <a class="header-anchor" href="#_1-3-端到端-end-to-end" aria-label="Permalink to “1.3 端到端（end-to-end）”">​</a></h3><p>直接从投影域/ k 空间到图像域学习映射，工程上需要更强的数据覆盖与更严格的泛化验证。</p><hr><h2 id="_2-优势与挑战-落地视角" tabindex="-1">2. 优势与挑战（落地视角） <a class="header-anchor" href="#_2-优势与挑战-落地视角" aria-label="Permalink to “2. 优势与挑战（落地视角）”">​</a></h2><p><strong>优势</strong></p><ul><li>低剂量/稀疏采样下显著提升视觉质量与指标</li><li>推理速度快于传统高质量迭代</li></ul><p><strong>挑战</strong></p><ul><li>数据分布偏移与跨中心泛化</li><li>可解释性与可控性（尤其是“幻觉”）</li><li>临床验证与标准化仍需时间</li></ul><hr><h2 id="_3-推荐文献-起步" tabindex="-1">3. 推荐文献（起步） <a class="header-anchor" href="#_3-推荐文献-起步" aria-label="Permalink to “3. 推荐文献（起步）”">​</a></h2><ol><li>Jin et al., “Deep Convolutional Neural Network for Inverse Problems in Imaging”, IEEE TIP, 2017.</li><li>Yang et al., “DuDoNet: Dual Domain Network for CT Metal Artifact Reduction”, CVPR, 2019.</li></ol><hr><h2 id="下一步" tabindex="-1">下一步 <a class="header-anchor" href="#下一步" aria-label="Permalink to “下一步”">​</a></h2><p>如果你要把“重建”落到可复现的小实验：建议直接进入第4章 Case Study（从环境搭建到指标评估）。</p>',26)])])}const _=a(i,[["render",o]]);export{u as __pageData,_ as default};
